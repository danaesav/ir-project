{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9dad999aea79a9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2ff08",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1923b85c6cac194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:39.776434Z",
     "start_time": "2025-04-01T00:48:36.606950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /home/weicheng/ir-project to Python path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2965/3639574956.py:18: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
      "  if not pt.started():\n",
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "/tmp/ipykernel_2965/3639574956.py:19: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "java is now started automatically with default settings. To force initialisation early, run:\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init()\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "PyTorch version: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# In Jupyter notebooks, __file__ is not defined\n",
    "# Instead, use the current working directory to modify the path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyterrier as pt\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize PyTerrier\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "from pyterrier.datasets import Dataset\n",
    "from pyterrier.measures import *\n",
    "from fast_forward.encoder import TASBEncoder, ContrieverEncoder\n",
    "from fast_forward.index import OnDiskIndex, Mode\n",
    "from fast_forward.util import Indexer\n",
    "from fast_forward.util.pyterrier import FFInterpolate, FFScore\n",
    "from pyterrier.terrier import Retriever\n",
    "\n",
    "from fusions.FFTM2C2 import FFTM2C2\n",
    "from fusions.experiment import fuse_convex_norm\n",
    "\n",
    "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da16c45d148213b",
   "metadata": {},
   "source": [
    "# Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982bb7afd490eb6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:52.159250Z",
     "start_time": "2025-04-01T00:48:39.793274Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "beir/scifact documents: 100%|██████████| 5183/5183 [00:02<00:00, 2304.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset Selection: https://pyterrier.readthedocs.io/en/latest/datasets.html\n",
    "dataset_name = \"irds:beir/scifact\"\n",
    "dataset = pt.get_dataset(dataset_name)\n",
    "testset = pt.get_dataset(dataset_name + \"/test\")\n",
    "\n",
    "# Indexing\n",
    "indexer = pt.IterDictIndexer(\n",
    "    str(Path.cwd()),  # this will be ignored\n",
    "    type=pt.index.IndexingType.MEMORY,\n",
    ")\n",
    "index_ref = indexer.index(dataset.get_corpus_iter(), fields=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d591fa21b95d460",
   "metadata": {},
   "source": [
    "# Model Configuration\n",
    "\n",
    "Setting up three retrieval models:\n",
    "1. BM25 - Classic lexical retrieval\n",
    "2. TASB - Neural retriever model\n",
    "3. Contriever - Neural retriever model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea43aa98b5f01b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:53.863126Z",
     "start_time": "2025-04-01T00:48:52.162208Z"
    }
   },
   "outputs": [],
   "source": [
    "# BM25\n",
    "bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "tasb_q_encoder =  tasb_d_encoder = TASBEncoder(device=device)\n",
    "con_q_encoder = con_d_encoder = ContrieverEncoder(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6581fc585edb730e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:54.641801Z",
     "start_time": "2025-04-01T00:48:53.870277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 2281120.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 2798542.43it/s]\n"
     ]
    }
   ],
   "source": [
    "safe_dataset_name = dataset_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "# Define index paths for both models\n",
    "tasb_index_path = Path(f\"../indexes/ffindex_{safe_dataset_name}_tasb.h5\")\n",
    "con_index_path = Path(f\"../indexes/ffindex_{safe_dataset_name}_con.h5\")\n",
    "\n",
    "def load_or_create_index(index_path: pathlib.Path, q_encoder, d_encoder):\n",
    "    print(index_path.exists())\n",
    "    try:\n",
    "        ff_index = OnDiskIndex.load(\n",
    "            index_path,\n",
    "            query_encoder=q_encoder,\n",
    "            mode=Mode.MAXP,\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        index_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        ff_index = OnDiskIndex(\n",
    "            index_path,\n",
    "            query_encoder=q_encoder,\n",
    "            mode=Mode.MAXP,\n",
    "        )\n",
    "        from fast_forward.util import Indexer\n",
    "\n",
    "        def docs_iter():\n",
    "            for d in dataset.get_corpus_iter():\n",
    "                yield {\"doc_id\": d[\"docno\"], \"text\": d[\"text\"]}\n",
    "\n",
    "        Indexer(ff_index, d_encoder, batch_size=8).from_dicts(docs_iter())\n",
    "\n",
    "    return ff_index.to_memory()\n",
    "\n",
    "tasb_index = load_or_create_index(tasb_index_path, tasb_q_encoder, tasb_d_encoder)\n",
    "con_index = load_or_create_index(con_index_path, con_q_encoder, con_d_encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9222ff28",
   "metadata": {},
   "source": [
    "## Create Retrieval Pipelines\n",
    "\n",
    "We create three pipelines:\n",
    "1. BM25 only\n",
    "2. BM25 re-ranked with TASB\n",
    "3. BM25 re-ranked with Contriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381b3dd75a2cda25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:53:17.291593Z",
     "start_time": "2025-04-01T00:53:17.288835Z"
    }
   },
   "outputs": [],
   "source": [
    "ff_tasb = FFScore(tasb_index)\n",
    "ff_con = FFScore(con_index)\n",
    "RANK_CUTOFF = 50  # Number of documents to retrieve with BM25 before re-ranking\n",
    "\n",
    "# Define retrieval pipelines\n",
    "pipeline_0 = (bm25 % RANK_CUTOFF)  # BM25 only\n",
    "pipeline_1 = bm25 % RANK_CUTOFF >> ff_tasb  # BM25 + TASB re-ranking\n",
    "pipeline_2 = bm25 % RANK_CUTOFF >> ff_con  # BM25 + Contriever re-ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d0290e708465b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:53:49.560038Z",
     "start_time": "2025-04-01T00:53:17.905921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:43:36.993 [main] WARN org.terrier.querying.ApplyTermPipeline -- The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_pipeline_result(pipeline: Retriever, ds: Dataset):\n",
    "    return pipeline.transform(ds.get_topics())\n",
    "\n",
    "res_1 = get_pipeline_result(pipeline_0,testset)\n",
    "res_2 = get_pipeline_result(pipeline_1,testset)\n",
    "res_3 = get_pipeline_result(pipeline_2,testset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c87fe9",
   "metadata": {},
   "source": [
    "## Model Fusion\n",
    "\n",
    "Combine results from the three models using convex normalization,\n",
    "with weights 0.2 for BM25, 0.4 for TASB, and 0.4 for Contriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "337d8ee7fa723daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:53:49.660705Z",
     "start_time": "2025-04-01T00:53:49.565076Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n"
     ]
    }
   ],
   "source": [
    "fuse_min_max = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"min_max\",\n",
    "    normalization_method_2=\"min_max\",\n",
    "    normalization_method_3=\"min_max\",\n",
    ")\n",
    "\n",
    "fuse_t_min_max = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"theoretical_min_max\",\n",
    "    normalization_method_2=\"theoretical_min_max\",\n",
    "    normalization_method_3=\"theoretical_min_max\",\n",
    ")\n",
    "\n",
    "fuse_z_score = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"z_score\",\n",
    "    normalization_method_2=\"z_score\",\n",
    "    normalization_method_3=\"z_score\",\n",
    ")\n",
    "\n",
    "fuse_min_max_lexical = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"min_max\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n",
    "\n",
    "fuse_t_min_max_lexical = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"theoretical_min_max\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n",
    "\n",
    "fuse_z_score_lexical = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"z_score\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n",
    "\n",
    "fuse_clean = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"unnormalized\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779460b7",
   "metadata": {},
   "source": [
    "## Evaluation Results\n",
    "\n",
    "Compare performance of individual models vs fusion approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9948063237238843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:59:56.907455Z",
     "start_time": "2025-04-01T00:59:56.370325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@100</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "      <th>nDCG@10 reject</th>\n",
       "      <th>nDCG@10 p-value corrected</th>\n",
       "      <th>AP@100 +</th>\n",
       "      <th>AP@100 -</th>\n",
       "      <th>AP@100 p-value</th>\n",
       "      <th>AP@100 reject</th>\n",
       "      <th>AP@100 p-value corrected</th>\n",
       "      <th>RR@10 +</th>\n",
       "      <th>RR@10 -</th>\n",
       "      <th>RR@10 p-value</th>\n",
       "      <th>RR@10 reject</th>\n",
       "      <th>RR@10 p-value corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25</td>\n",
       "      <td>0.672167</td>\n",
       "      <td>0.626235</td>\n",
       "      <td>0.632427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25+TASB</td>\n",
       "      <td>0.643090</td>\n",
       "      <td>0.604246</td>\n",
       "      <td>0.611757</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.081834</td>\n",
       "      <td>False</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>69.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.231077</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.280644</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bm25+Cont</td>\n",
       "      <td>0.664668</td>\n",
       "      <td>0.609543</td>\n",
       "      <td>0.622169</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.640590</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min_max_fusion</td>\n",
       "      <td>0.690287</td>\n",
       "      <td>0.650008</td>\n",
       "      <td>0.659679</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.162625</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.095701</td>\n",
       "      <td>False</td>\n",
       "      <td>0.861312</td>\n",
       "      <td>61.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.075014</td>\n",
       "      <td>False</td>\n",
       "      <td>0.675128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theoretical_min_max_fusion</td>\n",
       "      <td>0.700102</td>\n",
       "      <td>0.658921</td>\n",
       "      <td>0.666589</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>False</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>70.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>False</td>\n",
       "      <td>0.086167</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.102226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>z_score_fusion</td>\n",
       "      <td>0.699981</td>\n",
       "      <td>0.659639</td>\n",
       "      <td>0.667107</td>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>False</td>\n",
       "      <td>0.133770</td>\n",
       "      <td>71.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065489</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>False</td>\n",
       "      <td>0.082086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>min_max_fusion_lexical_only</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.616164</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.339675</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.383507</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>theoretical_min_max_fusion_lexical_only</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.616164</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.339675</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.383507</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>z_score_fusion_lexical_only</td>\n",
       "      <td>0.666123</td>\n",
       "      <td>0.629208</td>\n",
       "      <td>0.636914</td>\n",
       "      <td>66.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.686103</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.857770</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.795848</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no_normalization_fusion</td>\n",
       "      <td>0.689202</td>\n",
       "      <td>0.648462</td>\n",
       "      <td>0.655726</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>False</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.038208</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.039319</td>\n",
       "      <td>False</td>\n",
       "      <td>0.353873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name   nDCG@10    AP@100     RR@10  \\\n",
       "0                                     bm25  0.672167  0.626235  0.632427   \n",
       "1                                bm25+TASB  0.643090  0.604246  0.611757   \n",
       "2                                bm25+Cont  0.664668  0.609543  0.622169   \n",
       "3                           min_max_fusion  0.690287  0.650008  0.659679   \n",
       "4               theoretical_min_max_fusion  0.700102  0.658921  0.666589   \n",
       "5                           z_score_fusion  0.699981  0.659639  0.667107   \n",
       "6              min_max_fusion_lexical_only  0.647700  0.609164  0.616164   \n",
       "7  theoretical_min_max_fusion_lexical_only  0.647700  0.609164  0.616164   \n",
       "8              z_score_fusion_lexical_only  0.666123  0.629208  0.636914   \n",
       "9                  no_normalization_fusion  0.689202  0.648462  0.655726   \n",
       "\n",
       "   nDCG@10 +  nDCG@10 -  nDCG@10 p-value  nDCG@10 reject  \\\n",
       "0        NaN        NaN              NaN           False   \n",
       "1       64.0       65.0         0.081834           False   \n",
       "2       67.0       66.0         0.640590           False   \n",
       "3       68.0       42.0         0.162625           False   \n",
       "4       67.0       34.0         0.016661           False   \n",
       "5       67.0       33.0         0.014863           False   \n",
       "6       66.0       63.0         0.132066           False   \n",
       "7       66.0       63.0         0.132066           False   \n",
       "8       66.0       56.0         0.686103           False   \n",
       "9       58.0       29.0         0.078741           False   \n",
       "\n",
       "   nDCG@10 p-value corrected  AP@100 +  AP@100 -  AP@100 p-value  \\\n",
       "0                        NaN       NaN       NaN             NaN   \n",
       "1                   0.736508      69.0      71.0        0.231077   \n",
       "2                   1.000000      70.0      67.0        0.347563   \n",
       "3                   1.000000      72.0      46.0        0.095701   \n",
       "4                   0.149951      70.0      38.0        0.009574   \n",
       "5                   0.133770      71.0      36.0        0.007277   \n",
       "6                   1.000000      71.0      69.0        0.339675   \n",
       "7                   1.000000      71.0      69.0        0.339675   \n",
       "8                   1.000000      72.0      62.0        0.857770   \n",
       "9                   0.708667      66.0      34.0        0.038208   \n",
       "\n",
       "   AP@100 reject  AP@100 p-value corrected  RR@10 +  RR@10 -  RR@10 p-value  \\\n",
       "0          False                       NaN      NaN      NaN            NaN   \n",
       "1          False                  1.000000     56.0     64.0       0.280644   \n",
       "2          False                  1.000000     62.0     65.0       0.587228   \n",
       "3          False                  0.861312     61.0     42.0       0.075014   \n",
       "4          False                  0.086167     60.0     34.0       0.011358   \n",
       "5          False                  0.065489     60.0     33.0       0.009121   \n",
       "6          False                  1.000000     58.0     62.0       0.383507   \n",
       "7          False                  1.000000     58.0     62.0       0.383507   \n",
       "8          False                  1.000000     58.0     55.0       0.795848   \n",
       "9          False                  0.343874     48.0     28.0       0.039319   \n",
       "\n",
       "   RR@10 reject  RR@10 p-value corrected  \n",
       "0         False                      NaN  \n",
       "1         False                 1.000000  \n",
       "2         False                 1.000000  \n",
       "3         False                 0.675128  \n",
       "4         False                 0.102226  \n",
       "5         False                 0.082086  \n",
       "6         False                 1.000000  \n",
       "7         False                 1.000000  \n",
       "8         False                 1.000000  \n",
       "9         False                 0.353873  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "\n",
    "    [res_1,res_2,res_3,\n",
    "    fuse_min_max, \n",
    "    fuse_t_min_max, \n",
    "    fuse_z_score, \n",
    "    fuse_min_max_lexical,\n",
    "    fuse_t_min_max_lexical, \n",
    "    fuse_z_score_lexical,\n",
    "    fuse_clean],\n",
    "\n",
    "    testset.get_topics(),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "    names=['bm25', 'bm25+TASB', 'bm25+Cont', \n",
    "           'min_max_fusion', \n",
    "           'theoretical_min_max_fusion', \n",
    "           'z_score_fusion', \n",
    "           'min_max_fusion_lexical_only', \n",
    "           'theoretical_min_max_fusion_lexical_only', \n",
    "           'z_score_fusion_lexical_only',\n",
    "           'no_normalization_fusion'],\n",
    "    baseline=0,\n",
    "    correction=\"bonferroni\",\n",
    "    save_dir=\"./results\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ccee5e",
   "metadata": {},
   "source": [
    "Use unnormalized fusion of 3 models as baseline here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47c64f807c6ec711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/pipelines.py:299: UserWarning: save_dir is set, but the file './results/BM25.res.gz' already exists. If you are aware of are happy to reuse this file to speed up evaluation, set save_mode='reuse'; if you want to overwrite it, set save_mode='overwrite'. To make this condition an error, use save_mode='error'.\n",
      "  warn((\"save_dir is set, but the file '%s' already exists. If you are aware of are happy to reuse this \" % save_file)+\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/pipelines.py:299: UserWarning: save_dir is set, but the file './results/BM25+TASB.res.gz' already exists. If you are aware of are happy to reuse this file to speed up evaluation, set save_mode='reuse'; if you want to overwrite it, set save_mode='overwrite'. To make this condition an error, use save_mode='error'.\n",
      "  warn((\"save_dir is set, but the file '%s' already exists. If you are aware of are happy to reuse this \" % save_file)+\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/pipelines.py:299: UserWarning: save_dir is set, but the file './results/BM25+Cont.res.gz' already exists. If you are aware of are happy to reuse this file to speed up evaluation, set save_mode='reuse'; if you want to overwrite it, set save_mode='overwrite'. To make this condition an error, use save_mode='error'.\n",
      "  warn((\"save_dir is set, but the file '%s' already exists. If you are aware of are happy to reuse this \" % save_file)+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>R@10</th>\n",
       "      <th>nDCG@100</th>\n",
       "      <th>AP@100</th>\n",
       "      <th>RR@100</th>\n",
       "      <th>R@10 +</th>\n",
       "      <th>R@10 -</th>\n",
       "      <th>R@10 p-value</th>\n",
       "      <th>R@10 reject</th>\n",
       "      <th>R@10 p-value corrected</th>\n",
       "      <th>...</th>\n",
       "      <th>AP@100 +</th>\n",
       "      <th>AP@100 -</th>\n",
       "      <th>AP@100 p-value</th>\n",
       "      <th>AP@100 reject</th>\n",
       "      <th>AP@100 p-value corrected</th>\n",
       "      <th>RR@100 +</th>\n",
       "      <th>RR@100 -</th>\n",
       "      <th>RR@100 p-value</th>\n",
       "      <th>RR@100 reject</th>\n",
       "      <th>RR@100 p-value corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_normalization_fusion</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.708394</td>\n",
       "      <td>0.648462</td>\n",
       "      <td>0.659882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min_max_fusion</td>\n",
       "      <td>0.813556</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.650008</td>\n",
       "      <td>0.663905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.975908</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.856972</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.668284</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theoretical_min_max_fusion</td>\n",
       "      <td>0.826778</td>\n",
       "      <td>0.716833</td>\n",
       "      <td>0.658921</td>\n",
       "      <td>0.670356</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.240236</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z_score_fusion</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>0.717007</td>\n",
       "      <td>0.659639</td>\n",
       "      <td>0.670897</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.272013</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.138348</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.171798</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min_max_fusion_lexical_only</td>\n",
       "      <td>0.774556</td>\n",
       "      <td>0.675335</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.621954</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>True</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>39.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>theoretical_min_max_fusion_lexical_only</td>\n",
       "      <td>0.774556</td>\n",
       "      <td>0.675335</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.621954</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>True</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>39.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>z_score_fusion_lexical_only</td>\n",
       "      <td>0.786222</td>\n",
       "      <td>0.691125</td>\n",
       "      <td>0.629208</td>\n",
       "      <td>0.642069</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>False</td>\n",
       "      <td>0.101484</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.088589</td>\n",
       "      <td>False</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.128139</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.814333</td>\n",
       "      <td>0.691317</td>\n",
       "      <td>0.626235</td>\n",
       "      <td>0.636190</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.972730</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.038208</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.032095</td>\n",
       "      <td>False</td>\n",
       "      <td>0.288853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BM25+TASB</td>\n",
       "      <td>0.771222</td>\n",
       "      <td>0.671378</td>\n",
       "      <td>0.604246</td>\n",
       "      <td>0.617633</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>True</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>True</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>36.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>True</td>\n",
       "      <td>0.023427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BM25+Cont</td>\n",
       "      <td>0.829278</td>\n",
       "      <td>0.680282</td>\n",
       "      <td>0.609543</td>\n",
       "      <td>0.625360</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.324404</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>False</td>\n",
       "      <td>0.098712</td>\n",
       "      <td>48.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.028145</td>\n",
       "      <td>False</td>\n",
       "      <td>0.253308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name      R@10  nDCG@100    AP@100  \\\n",
       "0                  no_normalization_fusion  0.813889  0.708394  0.648462   \n",
       "1                           min_max_fusion  0.813556  0.709600  0.650008   \n",
       "2               theoretical_min_max_fusion  0.826778  0.716833  0.658921   \n",
       "3                           z_score_fusion  0.824111  0.717007  0.659639   \n",
       "4              min_max_fusion_lexical_only  0.774556  0.675335  0.609164   \n",
       "5  theoretical_min_max_fusion_lexical_only  0.774556  0.675335  0.609164   \n",
       "6              z_score_fusion_lexical_only  0.786222  0.691125  0.629208   \n",
       "7                                     BM25  0.814333  0.691317  0.626235   \n",
       "8                                BM25+TASB  0.771222  0.671378  0.604246   \n",
       "9                                BM25+Cont  0.829278  0.680282  0.609543   \n",
       "\n",
       "     RR@100  R@10 +  R@10 -  R@10 p-value  R@10 reject  \\\n",
       "0  0.659882     NaN     NaN           NaN        False   \n",
       "1  0.663905     7.0     7.0      0.975908        False   \n",
       "2  0.670356     9.0     6.0      0.240236        False   \n",
       "3  0.670897     7.0     4.0      0.272013        False   \n",
       "4  0.621954     4.0    15.0      0.003559         True   \n",
       "5  0.621954     4.0    15.0      0.003559         True   \n",
       "6  0.642069     3.0    11.0      0.011276        False   \n",
       "7  0.636190     9.0    13.0      0.972730        False   \n",
       "8  0.617633     4.0    16.0      0.002121         True   \n",
       "9  0.625360    15.0    12.0      0.324404        False   \n",
       "\n",
       "   R@10 p-value corrected  ...  AP@100 +  AP@100 -  AP@100 p-value  \\\n",
       "0                     NaN  ...       NaN       NaN             NaN   \n",
       "1                1.000000  ...      53.0      44.0        0.856972   \n",
       "2                1.000000  ...      51.0      34.0        0.200693   \n",
       "3                1.000000  ...      53.0      34.0        0.138348   \n",
       "4                0.032032  ...      45.0      73.0        0.002872   \n",
       "5                0.032032  ...      45.0      73.0        0.002872   \n",
       "6                0.101484  ...      42.0      67.0        0.088589   \n",
       "7                1.000000  ...      34.0      66.0        0.038208   \n",
       "8                0.019086  ...      40.0      80.0        0.001240   \n",
       "9                1.000000  ...      51.0      79.0        0.010968   \n",
       "\n",
       "   AP@100 reject  AP@100 p-value corrected  RR@100 +  RR@100 -  \\\n",
       "0          False                       NaN       NaN       NaN   \n",
       "1          False                  1.000000      46.0      43.0   \n",
       "2          False                  1.000000      43.0      32.0   \n",
       "3          False                  1.000000      44.0      33.0   \n",
       "4           True                  0.025847      39.0      70.0   \n",
       "5           True                  0.025847      39.0      70.0   \n",
       "6          False                  0.797297      37.0      63.0   \n",
       "7          False                  0.343874      33.0      55.0   \n",
       "8           True                  0.011159      36.0      75.0   \n",
       "9          False                  0.098712      48.0      73.0   \n",
       "\n",
       "   RR@100 p-value  RR@100 reject  RR@100 p-value corrected  \n",
       "0             NaN          False                       NaN  \n",
       "1        0.668284          False                  1.000000  \n",
       "2        0.225600          False                  1.000000  \n",
       "3        0.171798          False                  1.000000  \n",
       "4        0.005117           True                  0.046049  \n",
       "5        0.005117           True                  0.046049  \n",
       "6        0.128139          False                  1.000000  \n",
       "7        0.032095          False                  0.288853  \n",
       "8        0.002603           True                  0.023427  \n",
       "9        0.028145          False                  0.253308  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pt.Experiment(\n",
    "\n",
    "    [fuse_clean,\n",
    "    fuse_min_max, \n",
    "    fuse_t_min_max, \n",
    "    fuse_z_score, \n",
    "    fuse_min_max_lexical,\n",
    "    fuse_t_min_max_lexical, \n",
    "    fuse_z_score_lexical,\n",
    "    pipeline_0,\n",
    "    pipeline_1,\n",
    "    pipeline_2,\n",
    "    ],\n",
    "\n",
    "    testset.get_topics(),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[R@10, RR @ 100, nDCG @ 100, MAP @ 100],\n",
    "    names=['no_normalization_fusion',\n",
    "           'min_max_fusion', \n",
    "           'theoretical_min_max_fusion', \n",
    "           'z_score_fusion', \n",
    "           'min_max_fusion_lexical_only', \n",
    "           'theoretical_min_max_fusion_lexical_only', \n",
    "           'z_score_fusion_lexical_only',\n",
    "           'BM25',\n",
    "            'BM25+TASB',\n",
    "            'BM25+Cont'\n",
    "           ],\n",
    "    baseline=0,\n",
    "    correction=\"bonferroni\",\n",
    "    save_dir=\"./results\",\n",
    ")\n",
    "\n",
    "result.to_csv(f'results/{safe_dataset_name}_output.csv', index=False)\n",
    "\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
