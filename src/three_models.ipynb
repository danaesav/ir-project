{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9dad999aea79a9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2ff08",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1923b85c6cac194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:39.776434Z",
     "start_time": "2025-04-01T00:48:36.606950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /home/weicheng/ir-project to Python path\n",
      "Using device: cuda:0\n",
      "PyTorch version: 2.6.0+cu124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23722/3639574956.py:18: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
      "  if not pt.started():\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# In Jupyter notebooks, __file__ is not defined\n",
    "# Instead, use the current working directory to modify the path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyterrier as pt\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize PyTerrier\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "from pyterrier.datasets import Dataset\n",
    "from pyterrier.measures import *\n",
    "from fast_forward.encoder import TASBEncoder, ContrieverEncoder\n",
    "from fast_forward.index import OnDiskIndex, Mode\n",
    "from fast_forward.util import Indexer\n",
    "from fast_forward.util.pyterrier import FFInterpolate, FFScore\n",
    "from pyterrier.terrier import Retriever\n",
    "\n",
    "from fusions.FFTM2C2 import FFTM2C2\n",
    "from fusions.experiment import fuse_convex_norm\n",
    "\n",
    "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da16c45d148213b",
   "metadata": {},
   "source": [
    "# Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "982bb7afd490eb6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:52.159250Z",
     "start_time": "2025-04-01T00:48:39.793274Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] building docstore\n",
      "[INFO] [starting] opening zip file                                              \n",
      "[INFO] [starting] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scifact.zip\n",
      "                                                                                \n",
      "\u001b[A                                                                                                                       [INFO] [finished] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scifact.zip: [00:01] [2.82MB] [1.47MB/s]\n",
      "[INFO] [finished] opening zip file [2.48s]                                      \n",
      "docs_iter: 100%|█████████████████████████| 5183/5183 [00:02<00:00, 2002.38doc/s]\n",
      "[INFO] [finished] docs_iter: [00:02] [5183doc] [2001.95doc/s]\n",
      "[INFO] [finished] building docstore [2.59s]\n",
      "beir/scifact documents: 100%|██████████| 5183/5183 [00:01<00:00, 3318.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset Selection: https://pyterrier.readthedocs.io/en/latest/datasets.html\n",
    "dataset_name = \"irds:beir/scifact\"\n",
    "dataset = pt.get_dataset(dataset_name)\n",
    "testset = pt.get_dataset(dataset_name + \"/test\")\n",
    "\n",
    "# Indexing\n",
    "indexer = pt.IterDictIndexer(\n",
    "    str(Path.cwd()),  # this will be ignored\n",
    "    type=pt.index.IndexingType.MEMORY,\n",
    ")\n",
    "index_ref = indexer.index(dataset.get_corpus_iter(), fields=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d591fa21b95d460",
   "metadata": {},
   "source": [
    "# Model Configuration\n",
    "\n",
    "Setting up three retrieval models:\n",
    "1. BM25 - Classic lexical retrieval\n",
    "2. TASB - Neural retriever model\n",
    "3. Contriever - Neural retriever model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fea43aa98b5f01b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:53.863126Z",
     "start_time": "2025-04-01T00:48:52.162208Z"
    }
   },
   "outputs": [],
   "source": [
    "# BM25\n",
    "bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "tasb_q_encoder =  tasb_d_encoder = TASBEncoder(device=device)\n",
    "con_q_encoder = con_d_encoder = ContrieverEncoder(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6581fc585edb730e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:48:54.641801Z",
     "start_time": "2025-04-01T00:48:53.870277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 1823289.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 2253921.99it/s]\n"
     ]
    }
   ],
   "source": [
    "safe_dataset_name = dataset_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "# Define index paths for both models\n",
    "tasb_index_path = Path(f\"../indexes/ffindex_{safe_dataset_name}_tasb.h5\")\n",
    "con_index_path = Path(f\"../indexes/ffindex_{safe_dataset_name}_con.h5\")\n",
    "\n",
    "def load_or_create_index(index_path: pathlib.Path, q_encoder, d_encoder):\n",
    "    print(index_path.exists())\n",
    "    try:\n",
    "        ff_index = OnDiskIndex.load(\n",
    "            index_path,\n",
    "            query_encoder=q_encoder,\n",
    "            mode=Mode.MAXP,\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        index_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        ff_index = OnDiskIndex(\n",
    "            index_path,\n",
    "            query_encoder=q_encoder,\n",
    "            mode=Mode.MAXP,\n",
    "        )\n",
    "        from fast_forward.util import Indexer\n",
    "\n",
    "        def docs_iter():\n",
    "            for d in dataset.get_corpus_iter():\n",
    "                yield {\"doc_id\": d[\"docno\"], \"text\": d[\"text\"]}\n",
    "\n",
    "        Indexer(ff_index, d_encoder, batch_size=8).from_dicts(docs_iter())\n",
    "\n",
    "    return ff_index.to_memory()\n",
    "\n",
    "tasb_index = load_or_create_index(tasb_index_path, tasb_q_encoder, tasb_d_encoder)\n",
    "con_index = load_or_create_index(con_index_path, con_q_encoder, con_d_encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9222ff28",
   "metadata": {},
   "source": [
    "## Create Retrieval Pipelines\n",
    "\n",
    "We create three pipelines:\n",
    "1. BM25 only\n",
    "2. BM25 re-ranked with TASB\n",
    "3. BM25 re-ranked with Contriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "381b3dd75a2cda25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:53:17.291593Z",
     "start_time": "2025-04-01T00:53:17.288835Z"
    }
   },
   "outputs": [],
   "source": [
    "ff_tasb = FFScore(tasb_index)\n",
    "ff_con = FFScore(con_index)\n",
    "RANK_CUTOFF = 50  # Number of documents to retrieve with BM25 before re-ranking\n",
    "\n",
    "# Define retrieval pipelines\n",
    "pipeline_0 = (bm25 % RANK_CUTOFF)  # BM25 only\n",
    "pipeline_1 = bm25 % RANK_CUTOFF >> ff_tasb  # BM25 + TASB re-ranking\n",
    "pipeline_2 = bm25 % RANK_CUTOFF >> ff_con  # BM25 + Contriever re-ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28d0290e708465b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:53:49.560038Z",
     "start_time": "2025-04-01T00:53:17.905921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:48:18.419 [main] WARN org.terrier.querying.ApplyTermPipeline -- The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] opening zip file\n",
      "[INFO] [finished] opening zip file [1ms]\n",
      "[INFO] [starting] opening zip file\n",
      "[INFO] [finished] opening zip file [0ms]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_pipeline_result(pipeline: Retriever, ds: Dataset):\n",
    "    return pipeline.transform(ds.get_topics())\n",
    "\n",
    "res_1 = get_pipeline_result(pipeline_0,testset)\n",
    "res_2 = get_pipeline_result(pipeline_1,testset)\n",
    "res_3 = get_pipeline_result(pipeline_2,testset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c87fe9",
   "metadata": {},
   "source": [
    "## Model Fusion\n",
    "\n",
    "Combine results from the three models using convex normalization,\n",
    "with weights 0.2 for BM25, 0.4 for TASB, and 0.4 for Contriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337d8ee7fa723daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:53:49.660705Z",
     "start_time": "2025-04-01T00:53:49.565076Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
      "/home/weicheng/ir-project/env/lib/python3.12/site-packages/pyterrier/model.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rank\"] = df.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + FIRST_RANK\n"
     ]
    }
   ],
   "source": [
    "fuse_min_max = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"min_max\",\n",
    "    normalization_method_2=\"min_max\",\n",
    "    normalization_method_3=\"min_max\",\n",
    ")\n",
    "\n",
    "fuse_t_min_max = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"theoretical_min_max\",\n",
    "    normalization_method_2=\"theoretical_min_max\",\n",
    "    normalization_method_3=\"theoretical_min_max\",\n",
    ")\n",
    "\n",
    "fuse_z_score = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"z_score\",\n",
    "    normalization_method_2=\"z_score\",\n",
    "    normalization_method_3=\"z_score\",\n",
    ")\n",
    "\n",
    "fuse_min_max_lexical = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"min_max\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n",
    "\n",
    "fuse_t_min_max_lexical = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"theoretical_min_max\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n",
    "\n",
    "fuse_z_score_lexical = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"z_score\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n",
    "\n",
    "fuse_clean = fuse_convex_norm(\n",
    "    df1=res_1,\n",
    "    df2=res_2,\n",
    "    df3=res_3,\n",
    "    w1=0.2,\n",
    "    w2=0.4,\n",
    "    w3=0.4,\n",
    "    normalization_method_1=\"unnormalized\",\n",
    "    normalization_method_2=\"unnormalized\",\n",
    "    normalization_method_3=\"unnormalized\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779460b7",
   "metadata": {},
   "source": [
    "## Evaluation Results\n",
    "\n",
    "Compare performance of individual models vs fusion approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9948063237238843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:59:56.907455Z",
     "start_time": "2025-04-01T00:59:56.370325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@100</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "      <th>nDCG@10 reject</th>\n",
       "      <th>nDCG@10 p-value corrected</th>\n",
       "      <th>AP@100 +</th>\n",
       "      <th>AP@100 -</th>\n",
       "      <th>AP@100 p-value</th>\n",
       "      <th>AP@100 reject</th>\n",
       "      <th>AP@100 p-value corrected</th>\n",
       "      <th>RR@10 +</th>\n",
       "      <th>RR@10 -</th>\n",
       "      <th>RR@10 p-value</th>\n",
       "      <th>RR@10 reject</th>\n",
       "      <th>RR@10 p-value corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25</td>\n",
       "      <td>0.672167</td>\n",
       "      <td>0.626235</td>\n",
       "      <td>0.632427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25+TASB</td>\n",
       "      <td>0.643090</td>\n",
       "      <td>0.604246</td>\n",
       "      <td>0.611757</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.081834</td>\n",
       "      <td>False</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>69.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.231077</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.280644</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bm25+Cont</td>\n",
       "      <td>0.664668</td>\n",
       "      <td>0.609543</td>\n",
       "      <td>0.622169</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.640590</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min_max_fusion</td>\n",
       "      <td>0.690287</td>\n",
       "      <td>0.650008</td>\n",
       "      <td>0.659679</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.162625</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.095701</td>\n",
       "      <td>False</td>\n",
       "      <td>0.861312</td>\n",
       "      <td>61.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.075014</td>\n",
       "      <td>False</td>\n",
       "      <td>0.675128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theoretical_min_max_fusion</td>\n",
       "      <td>0.700102</td>\n",
       "      <td>0.658921</td>\n",
       "      <td>0.666589</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>False</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>70.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>False</td>\n",
       "      <td>0.086167</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>False</td>\n",
       "      <td>0.102226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>z_score_fusion</td>\n",
       "      <td>0.699981</td>\n",
       "      <td>0.659639</td>\n",
       "      <td>0.667107</td>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>False</td>\n",
       "      <td>0.133770</td>\n",
       "      <td>71.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065489</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>False</td>\n",
       "      <td>0.082086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>min_max_fusion_lexical_only</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.616164</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.339675</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.383507</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>theoretical_min_max_fusion_lexical_only</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.616164</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.339675</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.383507</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>z_score_fusion_lexical_only</td>\n",
       "      <td>0.666123</td>\n",
       "      <td>0.629208</td>\n",
       "      <td>0.636914</td>\n",
       "      <td>66.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.686103</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.857770</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.795848</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no_normalization_fusion</td>\n",
       "      <td>0.689202</td>\n",
       "      <td>0.648462</td>\n",
       "      <td>0.655726</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>False</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.038208</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.039319</td>\n",
       "      <td>False</td>\n",
       "      <td>0.353873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name   nDCG@10    AP@100     RR@10  \\\n",
       "0                                     bm25  0.672167  0.626235  0.632427   \n",
       "1                                bm25+TASB  0.643090  0.604246  0.611757   \n",
       "2                                bm25+Cont  0.664668  0.609543  0.622169   \n",
       "3                           min_max_fusion  0.690287  0.650008  0.659679   \n",
       "4               theoretical_min_max_fusion  0.700102  0.658921  0.666589   \n",
       "5                           z_score_fusion  0.699981  0.659639  0.667107   \n",
       "6              min_max_fusion_lexical_only  0.647700  0.609164  0.616164   \n",
       "7  theoretical_min_max_fusion_lexical_only  0.647700  0.609164  0.616164   \n",
       "8              z_score_fusion_lexical_only  0.666123  0.629208  0.636914   \n",
       "9                  no_normalization_fusion  0.689202  0.648462  0.655726   \n",
       "\n",
       "   nDCG@10 +  nDCG@10 -  nDCG@10 p-value  nDCG@10 reject  \\\n",
       "0        NaN        NaN              NaN           False   \n",
       "1       64.0       65.0         0.081834           False   \n",
       "2       67.0       66.0         0.640590           False   \n",
       "3       68.0       42.0         0.162625           False   \n",
       "4       67.0       34.0         0.016661           False   \n",
       "5       67.0       33.0         0.014863           False   \n",
       "6       66.0       63.0         0.132066           False   \n",
       "7       66.0       63.0         0.132066           False   \n",
       "8       66.0       56.0         0.686103           False   \n",
       "9       58.0       29.0         0.078741           False   \n",
       "\n",
       "   nDCG@10 p-value corrected  AP@100 +  AP@100 -  AP@100 p-value  \\\n",
       "0                        NaN       NaN       NaN             NaN   \n",
       "1                   0.736508      69.0      71.0        0.231077   \n",
       "2                   1.000000      70.0      67.0        0.347563   \n",
       "3                   1.000000      72.0      46.0        0.095701   \n",
       "4                   0.149951      70.0      38.0        0.009574   \n",
       "5                   0.133770      71.0      36.0        0.007277   \n",
       "6                   1.000000      71.0      69.0        0.339675   \n",
       "7                   1.000000      71.0      69.0        0.339675   \n",
       "8                   1.000000      72.0      62.0        0.857770   \n",
       "9                   0.708667      66.0      34.0        0.038208   \n",
       "\n",
       "   AP@100 reject  AP@100 p-value corrected  RR@10 +  RR@10 -  RR@10 p-value  \\\n",
       "0          False                       NaN      NaN      NaN            NaN   \n",
       "1          False                  1.000000     56.0     64.0       0.280644   \n",
       "2          False                  1.000000     62.0     65.0       0.587228   \n",
       "3          False                  0.861312     61.0     42.0       0.075014   \n",
       "4          False                  0.086167     60.0     34.0       0.011358   \n",
       "5          False                  0.065489     60.0     33.0       0.009121   \n",
       "6          False                  1.000000     58.0     62.0       0.383507   \n",
       "7          False                  1.000000     58.0     62.0       0.383507   \n",
       "8          False                  1.000000     58.0     55.0       0.795848   \n",
       "9          False                  0.343874     48.0     28.0       0.039319   \n",
       "\n",
       "   RR@10 reject  RR@10 p-value corrected  \n",
       "0         False                      NaN  \n",
       "1         False                 1.000000  \n",
       "2         False                 1.000000  \n",
       "3         False                 0.675128  \n",
       "4         False                 0.102226  \n",
       "5         False                 0.082086  \n",
       "6         False                 1.000000  \n",
       "7         False                 1.000000  \n",
       "8         False                 1.000000  \n",
       "9         False                 0.353873  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "\n",
    "    [res_1,res_2,res_3,\n",
    "    fuse_min_max, \n",
    "    fuse_t_min_max, \n",
    "    fuse_z_score, \n",
    "    fuse_min_max_lexical,\n",
    "    fuse_t_min_max_lexical, \n",
    "    fuse_z_score_lexical,\n",
    "    fuse_clean],\n",
    "\n",
    "    testset.get_topics(),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "    names=['bm25', 'bm25+TASB', 'bm25+Cont', \n",
    "           'min_max_fusion', \n",
    "           'theoretical_min_max_fusion', \n",
    "           'z_score_fusion', \n",
    "           'min_max_fusion_lexical_only', \n",
    "           'theoretical_min_max_fusion_lexical_only', \n",
    "           'z_score_fusion_lexical_only',\n",
    "           'no_normalization_fusion'],\n",
    "    baseline=0,\n",
    "    correction=\"bonferroni\",\n",
    "    save_dir=\"./results\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ccee5e",
   "metadata": {},
   "source": [
    "Use unnormalized fusion of 3 models as baseline here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47c64f807c6ec711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@100</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "      <th>nDCG@10 reject</th>\n",
       "      <th>nDCG@10 p-value corrected</th>\n",
       "      <th>AP@100 +</th>\n",
       "      <th>AP@100 -</th>\n",
       "      <th>AP@100 p-value</th>\n",
       "      <th>AP@100 reject</th>\n",
       "      <th>AP@100 p-value corrected</th>\n",
       "      <th>RR@10 +</th>\n",
       "      <th>RR@10 -</th>\n",
       "      <th>RR@10 p-value</th>\n",
       "      <th>RR@10 reject</th>\n",
       "      <th>RR@10 p-value corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_normalization_fusion</td>\n",
       "      <td>0.689202</td>\n",
       "      <td>0.648462</td>\n",
       "      <td>0.655726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min_max_fusion</td>\n",
       "      <td>0.690287</td>\n",
       "      <td>0.650008</td>\n",
       "      <td>0.659679</td>\n",
       "      <td>43.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.885804</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.856972</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.677079</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theoretical_min_max_fusion</td>\n",
       "      <td>0.700102</td>\n",
       "      <td>0.658921</td>\n",
       "      <td>0.666589</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.129890</td>\n",
       "      <td>False</td>\n",
       "      <td>0.779340</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.213537</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z_score_fusion</td>\n",
       "      <td>0.699981</td>\n",
       "      <td>0.659639</td>\n",
       "      <td>0.667107</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.098898</td>\n",
       "      <td>False</td>\n",
       "      <td>0.593388</td>\n",
       "      <td>53.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.138348</td>\n",
       "      <td>False</td>\n",
       "      <td>0.830089</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.161642</td>\n",
       "      <td>False</td>\n",
       "      <td>0.969851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min_max_fusion_lexical_only</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.616164</td>\n",
       "      <td>40.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>45.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>True</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>34.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>True</td>\n",
       "      <td>0.024735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>theoretical_min_max_fusion_lexical_only</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.616164</td>\n",
       "      <td>40.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>45.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>True</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>34.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>True</td>\n",
       "      <td>0.024735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>z_score_fusion_lexical_only</td>\n",
       "      <td>0.666123</td>\n",
       "      <td>0.629208</td>\n",
       "      <td>0.636914</td>\n",
       "      <td>37.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.020237</td>\n",
       "      <td>False</td>\n",
       "      <td>0.121420</td>\n",
       "      <td>42.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.088589</td>\n",
       "      <td>False</td>\n",
       "      <td>0.531532</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.113620</td>\n",
       "      <td>False</td>\n",
       "      <td>0.681719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name   nDCG@10    AP@100     RR@10  \\\n",
       "0                  no_normalization_fusion  0.689202  0.648462  0.655726   \n",
       "1                           min_max_fusion  0.690287  0.650008  0.659679   \n",
       "2               theoretical_min_max_fusion  0.700102  0.658921  0.666589   \n",
       "3                           z_score_fusion  0.699981  0.659639  0.667107   \n",
       "4              min_max_fusion_lexical_only  0.647700  0.609164  0.616164   \n",
       "5  theoretical_min_max_fusion_lexical_only  0.647700  0.609164  0.616164   \n",
       "6              z_score_fusion_lexical_only  0.666123  0.629208  0.636914   \n",
       "\n",
       "   nDCG@10 +  nDCG@10 -  nDCG@10 p-value  nDCG@10 reject  \\\n",
       "0        NaN        NaN              NaN           False   \n",
       "1       43.0       38.0         0.885804           False   \n",
       "2       43.0       30.0         0.129890           False   \n",
       "3       42.0       28.0         0.098898           False   \n",
       "4       40.0       59.0         0.000417            True   \n",
       "5       40.0       59.0         0.000417            True   \n",
       "6       37.0       52.0         0.020237           False   \n",
       "\n",
       "   nDCG@10 p-value corrected  AP@100 +  AP@100 -  AP@100 p-value  \\\n",
       "0                        NaN       NaN       NaN             NaN   \n",
       "1                   1.000000      53.0      44.0        0.856972   \n",
       "2                   0.779340      51.0      34.0        0.200693   \n",
       "3                   0.593388      53.0      34.0        0.138348   \n",
       "4                   0.002504      45.0      73.0        0.002872   \n",
       "5                   0.002504      45.0      73.0        0.002872   \n",
       "6                   0.121420      42.0      67.0        0.088589   \n",
       "\n",
       "   AP@100 reject  AP@100 p-value corrected  RR@10 +  RR@10 -  RR@10 p-value  \\\n",
       "0          False                       NaN      NaN      NaN            NaN   \n",
       "1          False                  1.000000     36.0     37.0       0.677079   \n",
       "2          False                  1.000000     35.0     28.0       0.213537   \n",
       "3          False                  0.830089     34.0     27.0       0.161642   \n",
       "4           True                  0.017231     34.0     57.0       0.004123   \n",
       "5           True                  0.017231     34.0     57.0       0.004123   \n",
       "6          False                  0.531532     31.0     50.0       0.113620   \n",
       "\n",
       "   RR@10 reject  RR@10 p-value corrected  \n",
       "0         False                      NaN  \n",
       "1         False                 1.000000  \n",
       "2         False                 1.000000  \n",
       "3         False                 0.969851  \n",
       "4          True                 0.024735  \n",
       "5          True                 0.024735  \n",
       "6         False                 0.681719  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pt.Experiment(\n",
    "\n",
    "    [fuse_clean,\n",
    "    fuse_min_max, \n",
    "    fuse_t_min_max, \n",
    "    fuse_z_score, \n",
    "    fuse_min_max_lexical,\n",
    "    fuse_t_min_max_lexical, \n",
    "    fuse_z_score_lexical,\n",
    "    ],\n",
    "\n",
    "    testset.get_topics(),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "    names=['no_normalization_fusion',\n",
    "           'min_max_fusion', \n",
    "           'theoretical_min_max_fusion', \n",
    "           'z_score_fusion', \n",
    "           'min_max_fusion_lexical_only', \n",
    "           'theoretical_min_max_fusion_lexical_only', \n",
    "           'z_score_fusion_lexical_only',\n",
    "           ],\n",
    "    baseline=0,\n",
    "    correction=\"bonferroni\",\n",
    "    save_dir=\"./results\",\n",
    ")\n",
    "\n",
    "result.to_csv(f'results/{safe_dataset_name}output.csv', index=False)\n",
    "\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
