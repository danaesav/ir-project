{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Information Retrieval",
   "id": "c601f55fab0da22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:37:15.301593Z",
     "start_time": "2025-03-27T13:37:15.298593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyterrier as pt\n",
    "from pathlib import Path\n",
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "from fast_forward.encoder import TASBEncoder\n",
    "import torch\n",
    "from fast_forward.index import OnDiskIndex, Mode\n",
    "from fast_forward.util import Indexer\n",
    "from fast_forward.util.pyterrier import FFInterpolate\n",
    "from fast_forward.util import Indexer\n",
    "\n",
    "from fusions.FFTM2C2 import FFTM2C2\n",
    "from fast_forward.util.pyterrier import FFScore\n",
    "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.__version__)"
   ],
   "id": "690c3d140187efb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fusion Functions",
   "id": "30ad81720161b5cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:37:15.317787Z",
     "start_time": "2025-03-27T13:37:15.313365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Implement fusion functions reference: \n",
    "# https://github.com/mrjleo/fast-forward-indexes/blob/main/src/fast_forward/util/pyterrier.py\n",
    "class FFRRF(pt.Transformer):\n",
    "    \"\"\"\n",
    "    Fusion function implementing Reciprocal Rank Fusion (RRF):\n",
    "    - Computes hard ranks for BM25 and neural scores.\n",
    "    - Final score is the sum of reciprocals: 1/(k + rank) for each.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=60):\n",
    "        self.k = k\n",
    "        super().__init__()\n",
    "        \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transform using the RRF fusion method.\"\"\"\n",
    "        new_df = df[[\"qid\", \"docno\", \"query\"]].copy()\n",
    "        bm25_rank = df['score_0'].rank(method='min', ascending=False)\n",
    "        neural_rank = df['score'].rank(method='min', ascending=False)\n",
    "        new_df['score'] = 1 / (self.k + bm25_rank) + 1 / (self.k + neural_rank)\n",
    "        return pt.model.add_ranks(new_df, single_query=False)\n",
    "\n",
    "\n",
    "class FFSRRF(pt.Transformer):\n",
    "    \"\"\"\n",
    "    Fusion function implementing Soft Reciprocal Rank Fusion (SRRF):\n",
    "    - Computes a soft rank for BM25 and neural scores using a logistic function.\n",
    "    - Final score is computed similarly to RRF, but using the soft ranks.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=60, beta=1.0):\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"Transform using the SRRF fusion method.\"\"\"\n",
    "        new_df = df[[\"qid\", \"docno\", \"query\"]].copy()\n",
    "\n",
    "        def compute_soft_rank(scores):\n",
    "            n = len(scores)\n",
    "            soft_ranks = np.ones(n)\n",
    "            for i in range(n):\n",
    "                soft_ranks[i] += np.sum(1 / (1 + np.exp(self.beta * (scores[i] - scores)))) - 1\n",
    "            return soft_ranks\n",
    "\n",
    "        bm25_scores = df['score_0'].values.astype(np.float32)\n",
    "        neural_scores = df['score'].values.astype(np.float32)\n",
    "        sr_bm25 = compute_soft_rank(bm25_scores)\n",
    "        sr_neural = compute_soft_rank(neural_scores)\n",
    "        new_df['score'] = 1 / (self.k + sr_bm25) + 1 / (self.k + sr_neural)\n",
    "        return pt.model.add_ranks(new_df, single_query=False)\n"
   ],
   "id": "1eb209887027a4b9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Choose Datasets",
   "id": "704b70bcdf89cab2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:37:26.179503Z",
     "start_time": "2025-03-27T13:37:15.318788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset Selection: https://pyterrier.readthedocs.io/en/latest/datasets.html\n",
    "dataset_name = \"irds:beir/fiqa\"\n",
    "dataset = pt.get_dataset(dataset_name)\n",
    "testset = pt.get_dataset(dataset_name + \"/test\")\n",
    "\n",
    "# Indexing\n",
    "indexer = pt.IterDictIndexer(\n",
    "    str(Path.cwd()),  # this will be ignored\n",
    "    type=pt.index.IndexingType.MEMORY,\n",
    ")\n",
    "index_ref = indexer.index(dataset.get_corpus_iter(), fields=[\"text\"])"
   ],
   "id": "563955bb99d43464",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "beir/fiqa documents: 100%|██████████| 57638/57638 [00:10<00:00, 5310.44it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set up Retrievers",
   "id": "e6c261ff533b0e38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:37:26.721747Z",
     "start_time": "2025-03-27T13:37:26.179503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fast_forward.encoder import ContrieverEncoder\n",
    "\n",
    "# BM25\n",
    "bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "\n",
    "# Encoding\n",
    "# To change the encoder, consult:\n",
    "# https://github.com/mrjleo/fast-forward-indexes/blob/main/src/fast_forward/encoder/transformer.py\n",
    "\n",
    "# Since china doesn't have access to huggingface, I have manually downloaded the model, feel free to comment this.\n",
    "# ------------------ From Here\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# Contriever taken from huggingface\n",
    "local_model_path = 'C:/Users/win10 pro/Desktop/Danae_temp/ir-project/huggingface/TASBEncoder'\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\n",
    "model = AutoModel.from_pretrained(local_model_path, local_files_only=True)\n",
    "q_encoder = d_encoder = TASBEncoder(model=local_model_path, device=device)\n",
    "# -------------------- To here\n",
    "\n",
    "# And uncomment this\n",
    "# q_encoder = d_encoder = TASBEncoder(device=device)"
   ],
   "id": "e4ef0eba5d4fca0b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:37:26.975001Z",
     "start_time": "2025-03-27T13:37:26.721747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "safe_dataset_name = dataset_name.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "ff_index_path = Path(f\"../indexes/ffindex_{safe_dataset_name}_tasb2.h5\")\n",
    "    # Path.cwd().joinpath(\"indexes\", f\"ffindex_{safe_dataset_name}_tasb2.h5\"))\n",
    "print(ff_index_path.exists())\n",
    "\n",
    "# Create parent directory if it doesn't exist.\n",
    "# try: \n",
    "ff_index = OnDiskIndex.load(\n",
    "    ff_index_path,\n",
    "    query_encoder=q_encoder,\n",
    "    mode=Mode.MAXP,\n",
    ")\n",
    "# except FileNotFoundError:\n",
    "#     ff_index_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "#     ff_index = OnDiskIndex(\n",
    "#         ff_index_path,\n",
    "#         query_encoder=q_encoder,\n",
    "#         mode=Mode.MAXP,\n",
    "#     )\n",
    "#     from fast_forward.util import Indexer\n",
    "#     def docs_iter():\n",
    "#         for d in dataset.get_corpus_iter():\n",
    "#             yield {\"doc_id\": d[\"docno\"], \"text\": d[\"text\"]}\n",
    "# \n",
    "#     Indexer(ff_index, d_encoder, batch_size=8).from_dicts(docs_iter())\n",
    "\n",
    "\n",
    "ff_index = ff_index.to_memory()"
   ],
   "id": "2e52109942650d37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57646/57646 [00:00<00:00, 449757.80it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get scores and setup fusion techniques",
   "id": "fd40e1b1233d43f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:37:32.845478Z",
     "start_time": "2025-03-27T13:37:26.976002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ff_score = FFScore(ff_index)\n",
    "candidates = (bm25 % 5)(testset.get_topics())\n",
    "re_ranked = ff_score(candidates)\n",
    "\n",
    "hybrid = bm25 % 1000 >> ff_score\n",
    "ff_int = FFInterpolate(alpha=0.5)\n",
    "ff_int(re_ranked)\n",
    "ff_tm2c2 = FFTM2C2()\n",
    "ff_tm2c2(re_ranked)\n",
    "ff_rrf = FFRRF()\n",
    "ff_srrf = FFSRRF()\n",
    "ff_rrf(re_ranked)\n",
    "ff_srrf(re_ranked)"
   ],
   "id": "9a13079476b8a192",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:37:26.995 [main] WARN org.terrier.querying.ApplyTermPipeline -- The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        qid   docno                                              query  \\\n",
       "0      9979   35369  what is the best way to invest in gold as a he...   \n",
       "1      9979   96351  what is the best way to invest in gold as a he...   \n",
       "2      9979  327271  what is the best way to invest in gold as a he...   \n",
       "3      9979  483734  what is the best way to invest in gold as a he...   \n",
       "4      9979   30584  what is the best way to invest in gold as a he...   \n",
       "...     ...     ...                                                ...   \n",
       "3235  10034   44955  tax implications of holding ewu or other such ...   \n",
       "3236  10034  181942  tax implications of holding ewu or other such ...   \n",
       "3237  10034  180146  tax implications of holding ewu or other such ...   \n",
       "3238  10034  197478  tax implications of holding ewu or other such ...   \n",
       "3239  10034  561750  tax implications of holding ewu or other such ...   \n",
       "\n",
       "         score  rank  \n",
       "0     0.004425     0  \n",
       "1     0.002624     2  \n",
       "2     0.002582     3  \n",
       "3     0.002737     1  \n",
       "4     0.001306     4  \n",
       "...        ...   ...  \n",
       "3235  0.001643     0  \n",
       "3236  0.001209     2  \n",
       "3237  0.001062     3  \n",
       "3238  0.001230     1  \n",
       "3239  0.000953     4  \n",
       "\n",
       "[3240 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>query</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9979</td>\n",
       "      <td>35369</td>\n",
       "      <td>what is the best way to invest in gold as a he...</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979</td>\n",
       "      <td>96351</td>\n",
       "      <td>what is the best way to invest in gold as a he...</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9979</td>\n",
       "      <td>327271</td>\n",
       "      <td>what is the best way to invest in gold as a he...</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9979</td>\n",
       "      <td>483734</td>\n",
       "      <td>what is the best way to invest in gold as a he...</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9979</td>\n",
       "      <td>30584</td>\n",
       "      <td>what is the best way to invest in gold as a he...</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>10034</td>\n",
       "      <td>44955</td>\n",
       "      <td>tax implications of holding ewu or other such ...</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>10034</td>\n",
       "      <td>181942</td>\n",
       "      <td>tax implications of holding ewu or other such ...</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>10034</td>\n",
       "      <td>180146</td>\n",
       "      <td>tax implications of holding ewu or other such ...</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>10034</td>\n",
       "      <td>197478</td>\n",
       "      <td>tax implications of holding ewu or other such ...</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>10034</td>\n",
       "      <td>561750</td>\n",
       "      <td>tax implications of holding ewu or other such ...</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3240 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment/Evaluation",
   "id": "4626ecd1c30e616b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:37:38.553187Z",
     "start_time": "2025-03-27T13:37:32.845478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = pt.Experiment(\n",
    "    [bm25, hybrid >> ff_int,  hybrid >> ff_tm2c2],\n",
    "    testset.get_topics(),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "    names=[\"BM25\", \"linear(alpha = 0.5)\", \"TM2C2\"],\n",
    "    baseline=0,\n",
    "    correction=\"bonferroni\"\n",
    ")\n",
    "\n",
    "print(result)"
   ],
   "id": "31c0f12d8068aa50",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DataFrame scores column dtype must be `int`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m result = \u001B[43mpt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mExperiment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mbm25\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhybrid\u001B[49m\u001B[43m \u001B[49m\u001B[43m>>\u001B[49m\u001B[43m \u001B[49m\u001B[43mff_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mhybrid\u001B[49m\u001B[43m \u001B[49m\u001B[43m>>\u001B[49m\u001B[43m \u001B[49m\u001B[43mff_tm2c2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtestset\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_topics\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtestset\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_qrels\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mRR\u001B[49m\u001B[43m \u001B[49m\u001B[43m@\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnDCG\u001B[49m\u001B[43m \u001B[49m\u001B[43m@\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMAP\u001B[49m\u001B[43m \u001B[49m\u001B[43m@\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mBM25\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlinear(alpha = 0.5)\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mTM2C2\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcorrection\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbonferroni\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m      9\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\pyterrier\\pipelines.py:652\u001B[39m, in \u001B[36mExperiment\u001B[39m\u001B[34m(retr_systems, topics, qrels, eval_metrics, names, perquery, dataframe, batch_size, filter_by_qrels, filter_by_topics, baseline, test, correction, correction_alpha, highlight, round, verbose, save_dir, save_mode, save_format, precompute_prefix, **kwargs)\u001B[39m\n\u001B[32m    649\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mUnrecognised save_mode \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % \u001B[38;5;28mstr\u001B[39m(save_format)) \n\u001B[32m    650\u001B[39m     save_file = os.path.join(save_dir, \u001B[33m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % (name, save_ext))\n\u001B[32m--> \u001B[39m\u001B[32m652\u001B[39m time, evalMeasuresDict = \u001B[43m_run_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    653\u001B[39m \u001B[43m    \u001B[49m\u001B[43msystem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecution_topics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m    654\u001B[39m \u001B[43m    \u001B[49m\u001B[43mperquery\u001B[49m\u001B[43m=\u001B[49m\u001B[43mperquery\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m    655\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m    656\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbackfill_qids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_topic_qids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mperquery\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    657\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43msave_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    658\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43msave_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    659\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_format\u001B[49m\u001B[43m=\u001B[49m\u001B[43msave_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    660\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    662\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m baseline \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    663\u001B[39m     evalDictsPerQ.append(evalMeasuresDict)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\pyterrier\\pipelines.py:356\u001B[39m, in \u001B[36m_run_and_evaluate\u001B[39m\u001B[34m(system, topics, qrels, metrics, pbar, save_mode, save_file, save_format, perquery, batch_size, backfill_qids)\u001B[39m\n\u001B[32m    352\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(res) == \u001B[32m0\u001B[39m:\n\u001B[32m    353\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m topics, but no results received from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % (\u001B[38;5;28mlen\u001B[39m(topics), \u001B[38;5;28mstr\u001B[39m(system)) )\n\u001B[32m    355\u001B[39m     evalMeasuresDict = _ir_measures_to_dict(\n\u001B[32m--> \u001B[39m\u001B[32m356\u001B[39m         \u001B[43mir_measures\u001B[49m\u001B[43m.\u001B[49m\u001B[43miter_calc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mres\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrename\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_irmeasures_columns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m, \n\u001B[32m    357\u001B[39m         metrics,\n\u001B[32m    358\u001B[39m         rev_mapping,\n\u001B[32m    359\u001B[39m         num_q,\n\u001B[32m    360\u001B[39m         perquery,\n\u001B[32m    361\u001B[39m         backfill_qids)\n\u001B[32m    362\u001B[39m     pbar.update()\n\u001B[32m    363\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\ir_measures\\providers\\base.py:96\u001B[39m, in \u001B[36mProvider.iter_calc\u001B[39m\u001B[34m(self, measures, qrels, run)\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     93\u001B[39m \u001B[33;03mYields per-topic metrics for these measures, qrels, and run.\u001B[39;00m\n\u001B[32m     94\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     95\u001B[39m \u001B[38;5;28mself\u001B[39m._check_available()\n\u001B[32m---> \u001B[39m\u001B[32m96\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter_calc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeasures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\ir_measures\\providers\\base.py:102\u001B[39m, in \u001B[36mProvider._iter_calc\u001B[39m\u001B[34m(self, measures, qrels, run)\u001B[39m\n\u001B[32m    101\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_iter_calc\u001B[39m(\u001B[38;5;28mself\u001B[39m, measures: Iterable[Measure], qrels: TYPE_QREL, run: TYPE_RUN):\n\u001B[32m--> \u001B[39m\u001B[32m102\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeasures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m)\u001B[49m.iter_calc(run)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\ir_measures\\providers\\fallback_provider.py:46\u001B[39m, in \u001B[36mFallbackProvider._evaluator\u001B[39m\u001B[34m(self, measures, qrels)\u001B[39m\n\u001B[32m     44\u001B[39m qrels_teed = QrelsConverter(qrels).tee(\u001B[38;5;28mlen\u001B[39m(provider_measure_pairs))\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m (provider, provider_measures), qrels \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(provider_measure_pairs, qrels_teed):\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m     evaluators.append(\u001B[43mprovider\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprovider_measures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(evaluators) == \u001B[32m1\u001B[39m:\n\u001B[32m     48\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m evaluators[\u001B[32m0\u001B[39m] \u001B[38;5;66;03m# skip the overhead of FallbackEvaluator if there's only one\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\ir_measures\\providers\\base.py:80\u001B[39m, in \u001B[36mProvider.evaluator\u001B[39m\u001B[34m(self, measures, qrels)\u001B[39m\n\u001B[32m     75\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     76\u001B[39m \u001B[33;03mReturns an :class:`~ir_measures.providers.Evaluator` for these measures and qrels, which\u001B[39;00m\n\u001B[32m     77\u001B[39m \u001B[33;03mcan efficiently process multiple runs.\u001B[39;00m\n\u001B[32m     78\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     79\u001B[39m \u001B[38;5;28mself\u001B[39m._check_available()\n\u001B[32m---> \u001B[39m\u001B[32m80\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeasures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\ir_measures\\providers\\ranx_provider.py:40\u001B[39m, in \u001B[36mRanxProvider._evaluator\u001B[39m\u001B[34m(self, measures, qrels)\u001B[39m\n\u001B[32m     36\u001B[39m qids = \u001B[38;5;28mset\u001B[39m(qrels[\u001B[33m'\u001B[39m\u001B[33mquery_id\u001B[39m\u001B[33m'\u001B[39m].unique())\n\u001B[32m     38\u001B[39m \u001B[38;5;66;03m# Depending on the measure params, we may need multiple invocations of ranx\u001B[39;00m\n\u001B[32m     39\u001B[39m \u001B[38;5;66;03m# (e.g., with different rel_level, since it only supports running with 1 rel_level at a time)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m invokers = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_build_invokers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeasures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqrels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m RanxEvaluator(\u001B[38;5;28mself\u001B[39m.ranx, measures, invokers, qrels, qids=qids)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\ir_measures\\providers\\ranx_provider.py:103\u001B[39m, in \u001B[36mRanxProvider._build_invokers\u001B[39m\u001B[34m(self, measures, qrels)\u001B[39m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    102\u001B[39m         these_qrels = qrels\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m     these_qrels = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mranx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mQrels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthese_qrels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_id_col\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mquery_id\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdoc_id_col\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdoc_id\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscore_col\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrelevance\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    104\u001B[39m     invokers.append(RanxInvoker(\u001B[38;5;28mself\u001B[39m.ranx, these_qrels, measure_map))\n\u001B[32m    106\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m invokers\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\ir-project\\Lib\\site-packages\\ranx\\data_structures\\qrels.py:301\u001B[39m, in \u001B[36mQrels.from_df\u001B[39m\u001B[34m(df, q_id_col, doc_id_col, score_col)\u001B[39m\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[32m    295\u001B[39m     df[q_id_col].dtype == \u001B[33m\"\u001B[39m\u001B[33mO\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    296\u001B[39m ), \u001B[33m\"\u001B[39m\u001B[33mDataFrame Query IDs column dtype must be `object` (string)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    297\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[32m    298\u001B[39m     df[doc_id_col].dtype == \u001B[33m\"\u001B[39m\u001B[33mO\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    299\u001B[39m ), \u001B[33m\"\u001B[39m\u001B[33mDataFrame Document IDs column dtype must be `object` (string)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    300\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[32m--> \u001B[39m\u001B[32m301\u001B[39m     df[score_col].dtype == np.int64\n\u001B[32m    302\u001B[39m ), \u001B[33m\"\u001B[39m\u001B[33mDataFrame scores column dtype must be `int`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    304\u001B[39m qrels_dict = (\n\u001B[32m    305\u001B[39m     df.groupby(q_id_col)[[doc_id_col, score_col]]\n\u001B[32m    306\u001B[39m     .apply(\u001B[38;5;28;01mlambda\u001B[39;00m g: {x[\u001B[32m0\u001B[39m]: x[\u001B[32m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m g.values.tolist()})\n\u001B[32m    307\u001B[39m     .to_dict()\n\u001B[32m    308\u001B[39m )\n\u001B[32m    310\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Qrels.from_dict(qrels_dict)\n",
      "\u001B[31mAssertionError\u001B[39m: DataFrame scores column dtype must be `int`"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2b7a401343dcb0ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
